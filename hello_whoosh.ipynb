{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook walks through using Whoosh for indexing and searching the Stanford movie reviews dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hat tip to Abhijeet Kumar for https://appliedmachinelearning.blog/2018/07/31/developing-a-fast-indexing-and-full-text-search-engine-with-whoosh-a-pure-python-library/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install Whoosh if needed\n",
    "# !pip install Whoosh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-01-22 14:58:19--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
      "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 84125825 (80M) [application/x-gzip]\n",
      "Saving to: ‘aclImdb_v1.tar.gz’\n",
      "\n",
      "aclImdb_v1.tar.gz   100%[===================>]  80.23M  22.0MB/s    in 5.9s    \n",
      "\n",
      "2019-01-22 14:58:25 (13.5 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar xzf aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove meta files\n",
    "!rm aclImdb/imdb.vocab\n",
    "!rm aclImdb/imdbEr.txt\n",
    "!rm aclImdb/README\n",
    "!rm aclImdb/train/labeledBow.feat\n",
    "!rm aclImdb/train/unsupBow.feat\n",
    "!rm aclImdb/train/urls_neg.txt\n",
    "!rm aclImdb/train/urls_pos.txt\n",
    "!rm aclImdb/train/urls_unsup.txt\n",
    "!rm aclImdb/test/labeledBow.feat\n",
    "!rm aclImdb/test/urls_neg.txt\n",
    "!rm aclImdb/test/urls_pos.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data ready to go, lets build an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrub the files on the fly\n",
    "def get_cleaned_string(in_string):\n",
    "    safechars = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890 -./'\n",
    "    cleaned_list = []\n",
    "    for s in in_string:\n",
    "        if s in safechars:\n",
    "            cleaned_list.append(s)\n",
    "        else:\n",
    "            cleaned_list.append(' ')\n",
    "    return ''.join(cleaned_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "\n",
    "from whoosh.index import create_in\n",
    "from whoosh.fields import Schema, TEXT, ID\n",
    "import sys\n",
    " \n",
    "def createSearchableData(root):   \n",
    " \n",
    "    '''\n",
    "    Schema definition: title(name of file), path(as ID), content(indexed\n",
    "    but not stored),textdata (stored text content)\n",
    "    '''\n",
    "    schema = Schema(title=TEXT(stored=True),path=ID(stored=True),\\\n",
    "              content=TEXT,textdata=TEXT(stored=True))\n",
    "    if not os.path.exists(\"indexdir\"):\n",
    "        os.mkdir(\"indexdir\")\n",
    " \n",
    "    # Creating a index writer to add document as per schema\n",
    "    ix = create_in(\"indexdir\",schema)\n",
    "    writer = ix.writer()\n",
    "     \n",
    "    for filename in glob.iglob(root + '/**/*.txt', recursive=True):\n",
    "        with open(filename) as f:\n",
    "            data = f.read().replace('\\n', '')\n",
    "            text = get_cleaned_string(data)\n",
    "            writer.add_document(title=os.path.basename(f.name), path=os.path.realpath(f.name),content=text,textdata=text)\n",
    "    writer.commit()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the old index and rebuild for this data domain\n",
    "!rm -rdf indexdir\n",
    "root = \"aclImdb\"\n",
    "createSearchableData(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have built the index, lets query it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "results[0]: Results only has 0 hits",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-a19b763c8d43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         print(results[i]['title'], str(results[i].score),\n\u001b[0m\u001b[1;32m     17\u001b[0m         results[i]['textdata'])\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/whoosh/searching.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    995\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m                 raise IndexError(\"results[%r]: Results only has %s hits\"\n\u001b[0;32m--> 997\u001b[0;31m                                  % (n, len(self.top_n)))\n\u001b[0m\u001b[1;32m    998\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mHit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop_n\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop_n\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: results[0]: Results only has 0 hits"
     ]
    }
   ],
   "source": [
    "from whoosh.qparser import QueryParser\n",
    "from whoosh import scoring\n",
    "from whoosh.index import open_dir\n",
    " \n",
    "ix = open_dir(\"indexdir\")\n",
    " \n",
    "# query_str is query string\n",
    "query_str = \"James Bond\"\n",
    "# Top 'n' documents as result\n",
    "topN = 10\n",
    " \n",
    "with ix.searcher(weighting=scoring.Frequency) as searcher:\n",
    "    query = QueryParser(\"content\", ix.schema).parse(query_str)\n",
    "    results = searcher.search(query,limit=topN)\n",
    "    print(type(results))\n",
    "    for i in range(topN):\n",
    "        print(results[i]['title'], str(results[i].score),\n",
    "        results[i]['textdata'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
